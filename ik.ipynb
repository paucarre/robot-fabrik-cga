{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.tensordict import TensorDict, TensorDictBase\n",
    "from torch import nn\n",
    "\n",
    "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec\n",
    "from torchrl.envs import (\n",
    "    CatTensors,\n",
    "    EnvBase,\n",
    "    Transform,\n",
    "    TransformedEnv,\n",
    "    UnsqueezeTransform,\n",
    ")\n",
    "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
    "from torchrl.envs.utils import check_env_specs, step_mdp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from pytorch3d import transforms\n",
    "import math\n",
    "from linguamechanica.kinematics import DifferentiableOpenChainMechanism\n",
    "from linguamechanica.kinematics import UrdfRobotLibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_done_threshold = 1e-3\n",
    "weights = torch.Tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0]).cuda()\n",
    "urdf_robot = UrdfRobotLibrary.dobot_cr5()\n",
    "chain_index = 0\n",
    "used_open_chain = urdf_robot.extract_open_chains(0.3)[chain_index].to(weights.device)\n",
    "thetas_count = used_open_chain.screws.shape[0]\n",
    "pose_count = 6\n",
    "on_manifold_count = thetas_count + pose_count + pose_count\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_open_chain.screws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 1.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1470, 1.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_open_chain.initial_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.1470, -0.0000, -0.0000, -0.0000],\n",
       "        [0.0000, 0.0000, 0.1470, -0.0000, -0.0000, -0.0000],\n",
       "        [0.0000, 0.0000, 0.1470, -0.0000, -0.0000, 1.5000]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas = torch.Tensor([[0.0],[0.0],[1.5]]).cuda()\n",
    "transformation = used_open_chain.forward_transformation(\n",
    "    thetas\n",
    ")\n",
    "pose = transforms.se3_log_map(transformation.get_matrix())\n",
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_open_chain = used_open_chain.to(thetas.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.1470, -0.0000, -0.0000, 1.0000],\n",
       "        [0.0000, 0.0000, 0.1470, -0.0000, -0.0000, -0.0000],\n",
       "        [0.0000, 0.0000, 0.1470, -0.0000, -0.0000, 0.5000]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_thetas = torch.Tensor([[1.0],[0.0],[0.5]]).cuda()\n",
    "target_transformation = used_open_chain.forward_transformation(\n",
    "    target_thetas\n",
    ")\n",
    "target_pose = transforms.se3_log_map(target_transformation.get_matrix())\n",
    "target_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_pose(open_chain, thetas, target_pose):\n",
    "    #print(\"compute_error_pose\", thetas.shape, target_pose.shape)\n",
    "    #print(\"thetas causing nans\", thetas)\n",
    "    current_transformation = open_chain.forward_transformation(thetas)\n",
    "    target_transformation = transforms.se3_exp_map(target_pose)\n",
    "    #print(\"current_transformation\")\n",
    "    #print(current_transformation.get_matrix())\n",
    "    #print(\"target_transformation\")\n",
    "    #print(target_transformation)\n",
    "    current_trans_to_target = current_transformation.compose(\n",
    "        transforms.Transform3d(matrix=target_transformation).inverse()\n",
    "    )\n",
    "    current_trans_to_target = current_trans_to_target.to(thetas.device).get_matrix()\n",
    "    #print(\"current_trans_to_target\")\n",
    "    #print(current_trans_to_target)\n",
    "    error_pose = transforms.se3_log_map(current_trans_to_target)\n",
    "    return error_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -1.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_error_pose(used_open_chain, thetas, target_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def force_parameters_within_bounds(thetas):\n",
    "#    thetas[thetas >  math.pi] -= 2.0 * torch.pi\n",
    "#    thetas[thetas < -math.pi] += 2.0 * torch.pi\n",
    "#    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reward(thetas, target_pose, weights, error_done_threshold, open_chain):\n",
    "    if len(thetas.shape) == 1:\n",
    "        thetas = thetas.unsqueeze(0)\n",
    "    if len(target_pose.shape) == 1:\n",
    "        target_pose = target_pose.unsqueeze(0)\n",
    "    open_chain = open_chain.to(thetas.device)\n",
    "    #print(\"!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    #print(\"thetas\", thetas)\n",
    "    #print(\"target_pose\", target_pose.shape)\n",
    "    #print(\"target_pose\", target_pose)\n",
    "    #print(\"!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    error_pose = compute_error_pose(\n",
    "        open_chain, thetas, target_pose\n",
    "    )\n",
    "    weights = weights.to(thetas.device)\n",
    "    pose_error = DifferentiableOpenChainMechanism.compute_weighted_error(\n",
    "        error_pose, weights\n",
    "    )\n",
    "    done = pose_error < error_done_threshold\n",
    "    reward = - pose_error\n",
    "    return reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angles = torch.Tensor([0.1, -0.1, 0.2, -0.2])\n",
    "angles_sin = angles.sin()\n",
    "angles_cos = angles.cos()\n",
    "torch.atan2(angles_sin, angles_cos) - angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def _step(self, tensordict):\n",
    "    thetas = torch.atan2(tensordict[\"thetas_sin\"], tensordict[\"thetas_cos\"])\n",
    "    theta_deltas = tensordict[\"action\"]\n",
    "    #print(\"thetas\", thetas.shape)\n",
    "    #print(\"theta_deltas\", theta_deltas.shape)\n",
    "    theta_deltas_sin, theta_deltas_cos = None, None\n",
    "    if len(theta_deltas.shape) == 2:\n",
    "        theta_deltas_sin = theta_deltas[:, 0:1]\n",
    "        theta_deltas_cos = theta_deltas[:, 1:2]\n",
    "    else:\n",
    "        theta_deltas_sin = theta_deltas[0]\n",
    "        theta_deltas_cos = theta_deltas[1]\n",
    "    theta_deltas = torch.atan2(theta_deltas_sin, theta_deltas_cos)\n",
    "    \n",
    "    #print(\"theta_deltas\", theta_deltas.shape)\n",
    "    #print(\"thetas\", thetas.shape)\n",
    "    #max_theta_deltas = tensordict[\"params\", \"max_theta_deltas\"]\n",
    "    #print(thetas.shape, theta_deltas.shape)\n",
    "    new_thetas = thetas + (theta_deltas * 1.000)\n",
    "    #new_thetas = new_thetas.clamp(-max_theta_deltas, max_theta_deltas)\n",
    "    target_pose = tensordict[\"target_pose\"]\n",
    "    #print(\"target_pose in _step\", target_pose)\n",
    "    #print(\"STEP\", f\"Target: {target_pose}\", f\"Thetas: {thetas}\", f\"New Thetas: {new_thetas}\")\n",
    "    #TODO: I have no idea if this is a good idea or not\n",
    "    #new_thetas = force_parameters_within_bounds(new_thetas)\n",
    "    #print(\"----------------------------\")\n",
    "    #print(\"new_thetas.shape\", new_thetas.shape)\n",
    "    #print(\"target_pose\", target_pose)\n",
    "    #print(\"weights.shape\", weights.shape)\n",
    "    #print(\"----------------------------\")\n",
    "    reward, done = compute_reward(new_thetas, target_pose, weights, error_done_threshold, self.open_chain)\n",
    "    done = torch.zeros_like(reward, dtype=torch.bool)\n",
    "    out = TensorDict(\n",
    "        {\n",
    "            \"next\": {\n",
    "                \"thetas_sin\": new_thetas.sin(),\n",
    "                \"thetas_cos\": new_thetas.cos(),\n",
    "                \"target_pose\": target_pose,\n",
    "                \"params\": tensordict[\"params\"],\n",
    "                \"reward\": reward,\n",
    "                \"done\": done,\n",
    "            }\n",
    "        },\n",
    "        tensordict.shape,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniformly_sample_parameters_within_constraints(open_chain, batch_size):\n",
    "    samples = []\n",
    "    for sample_idx in range(batch_size):\n",
    "        coordinates = []\n",
    "        for i in range(len(open_chain.joint_limits)):\n",
    "            # TODO: check if unconstrained works\n",
    "            coordinates.append(\n",
    "                random.uniform(\n",
    "                    open_chain.joint_limits[i][0],\n",
    "                    open_chain.joint_limits[i][1],\n",
    "                )\n",
    "            )\n",
    "        samples.append(torch.Tensor(coordinates).unsqueeze(0))\n",
    "    return torch.cat(samples, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_target_pose(target_thetas, open_chain):\n",
    "    if len(target_thetas.shape) == 1:\n",
    "        target_thetas = target_thetas.unsqueeze(0)\n",
    "    open_chain = open_chain.to(target_thetas.device)\n",
    "    target_transformation = open_chain.forward_transformation(\n",
    "        target_thetas\n",
    "    )\n",
    "    target_pose = transforms.se3_log_map(\n",
    "        target_transformation.get_matrix()\n",
    "    )\n",
    "    if target_thetas.shape[0] == 1:\n",
    "        target_thetas = target_thetas.squeeze(0)\n",
    "    #print(\"generate_random_target_pose\", target_pose)\n",
    "    return target_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def _reset(self, tensordict):\n",
    "    if tensordict is None or tensordict.is_empty():\n",
    "        # if no tensordict is passed, we generate a single set of hyperparameters\n",
    "        # Otherwise, we assume that the input tensordict contains all the relevant\n",
    "        # parameters to get started.\n",
    "        tensordict = self.gen_params(batch_size=self.batch_size)\n",
    "    batch_size = 1 if len(tensordict.shape) == 0 else tensordict.shape[0]\n",
    "    thetas = uniformly_sample_parameters_within_constraints(self.open_chain, batch_size).to(device=self.device)\n",
    "    if batch_size == 1:\n",
    "        thetas = thetas.squeeze(0)    \n",
    "    #thetas = force_parameters_within_bounds(thetas)\n",
    "    #TODO: randommize this better\n",
    "    target_thetas = thetas + torch.randn(thetas.shape).to(self.device)\n",
    "    #target_thetas = force_parameters_within_bounds(target_thetas)\n",
    "    target_pose   = generate_random_target_pose(target_thetas, self.open_chain)\n",
    "    if batch_size == 1:\n",
    "        target_pose = target_pose.squeeze(0)\n",
    "    #print(\"target_pose.shape\", target_pose.shape)\n",
    "    out = TensorDict(\n",
    "        {\n",
    "            \"thetas_sin\": thetas.sin(),\n",
    "            \"thetas_cos\": thetas.cos(),\n",
    "            \"target_pose\": target_pose,\n",
    "            \"params\": tensordict[\"params\"],\n",
    "        },\n",
    "        batch_size=tensordict.shape,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def _make_spec(self, td_params):\n",
    "    # Under the hood, this will populate self.output_spec[\"observation\"]\n",
    "    self.observation_spec = CompositeSpec(\n",
    "        thetas_sin=BoundedTensorSpec(\n",
    "            minimum=-torch.ones(thetas_count) * torch.pi,\n",
    "            maximum= torch.ones(thetas_count) * torch.pi,\n",
    "            shape=(thetas_count),\n",
    "            dtype=torch.float32,\n",
    "        ),\n",
    "        thetas_cos=BoundedTensorSpec(\n",
    "            minimum=-torch.ones(thetas_count) * torch.pi,\n",
    "            maximum= torch.ones(thetas_count) * torch.pi,\n",
    "            shape=(thetas_count),\n",
    "            dtype=torch.float32,\n",
    "        ),\n",
    "        #TODO: bounds are wrong. They need to be the ones in the robot constraints\n",
    "        target_pose=BoundedTensorSpec(\n",
    "            minimum=-torch.ones(pose_count) * 10000.0,\n",
    "            maximum= torch.ones(pose_count) * 10000.0,\n",
    "            shape=(pose_count),\n",
    "            dtype=torch.float32,\n",
    "        ),\n",
    "        # we need to add the \"params\" to the observation specs, as we want\n",
    "        # to pass it at each step during a rollout\n",
    "        params=make_composite_from_td(td_params[\"params\"]),\n",
    "        shape=(),\n",
    "    )\n",
    "    # since the environment is stateless, we expect the previous output as input.\n",
    "    # For this, EnvBase expects some state_spec to be available\n",
    "    self.state_spec = self.observation_spec.clone()\n",
    "    # action-spec will be automatically wrapped in input_spec when\n",
    "    # `self.action_spec = spec` will be called supported\n",
    "    #TODO: bounds are wrong\n",
    "    self.action_spec = BoundedTensorSpec(\n",
    "        minimum=-torch.ones(thetas_count * 2) * 100000.0,\n",
    "        maximum=+torch.ones(thetas_count * 2) * 100000.0,\n",
    "        shape=(thetas_count * 2),\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "    self.reward_spec = UnboundedContinuousTensorSpec(shape=(*td_params.shape, 1))\n",
    "\n",
    "\n",
    "def make_composite_from_td(td):\n",
    "    # custom funtion to convert a tensordict in a similar spec structure\n",
    "    # of unbounded values.\n",
    "    composite = CompositeSpec(\n",
    "        {\n",
    "            key: make_composite_from_td(tensor)\n",
    "            if isinstance(tensor, TensorDictBase)\n",
    "            else UnboundedContinuousTensorSpec(\n",
    "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
    "            )\n",
    "            for key, tensor in td.items()\n",
    "        },\n",
    "        shape=td.shape,\n",
    "    )\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def _set_seed(self, seed: Optional[int]):\n",
    "    rng = torch.manual_seed(seed)\n",
    "    self.rng = rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def gen_params(batch_size=None) -> TensorDictBase:\n",
    "    if batch_size is None:\n",
    "        batch_size = []\n",
    "    td = TensorDict(\n",
    "        {\n",
    "            \"params\": TensorDict(\n",
    "                {\n",
    "                    \"max_theta_deltas\": torch.ones(thetas_count) * torch.pi,\n",
    "                },\n",
    "                [],\n",
    "            )\n",
    "        },\n",
    "        [],\n",
    "    )\n",
    "    if batch_size:\n",
    "        td = td.expand(batch_size).contiguous()\n",
    "    return td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class InverseKinematicsEnv(EnvBase):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 30,\n",
    "    }\n",
    "    batch_locked = False\n",
    "\n",
    "    def __init__(self, open_chain=None, td_params=None, seed=None, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        if td_params is None:\n",
    "            td_params = self.gen_params()\n",
    "        self.open_chain = open_chain\n",
    "        super().__init__(device=device, batch_size=[])\n",
    "        self._make_spec(td_params)\n",
    "        if seed is None:\n",
    "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
    "        self.set_seed(seed)\n",
    "\n",
    "    # Helpers: _make_step and gen_params\n",
    "    gen_params = staticmethod(gen_params)\n",
    "    _make_spec = _make_spec\n",
    "\n",
    "    # Mandatory methods: _step, _reset and _set_seed\n",
    "    _reset = _reset\n",
    "    _step = _step#staticmethod(_step)\n",
    "    _set_seed = _set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "env = InverseKinematicsEnv(open_chain=used_open_chain)\n",
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at our specs to have a visual representation of the environment\n",
    "signature:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_spec: CompositeSpec(\n",
      "    thetas_sin: BoundedTensorSpec(\n",
      "        shape=torch.Size([1]),\n",
      "        space=ContinuousBox(\n",
      "            minimum=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True), \n",
      "            maximum=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    thetas_cos: BoundedTensorSpec(\n",
      "        shape=torch.Size([1]),\n",
      "        space=ContinuousBox(\n",
      "            minimum=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True), \n",
      "            maximum=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    target_pose: BoundedTensorSpec(\n",
      "        shape=torch.Size([6]),\n",
      "        space=ContinuousBox(\n",
      "            minimum=Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float32, contiguous=True), \n",
      "            maximum=Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    params: CompositeSpec(\n",
      "        max_theta_deltas: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([1]),\n",
      "            space=ContinuousBox(\n",
      "                minimum=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True), \n",
      "                maximum=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))\n",
      "state_spec: CompositeSpec(\n",
      "    thetas_sin: BoundedTensorSpec(\n",
      "        shape=torch.Size([1]),\n",
      "        space=ContinuousBox(\n",
      "            minimum=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True), \n",
      "            maximum=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    thetas_cos: BoundedTensorSpec(\n",
      "        shape=torch.Size([1]),\n",
      "        space=ContinuousBox(\n",
      "            minimum=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True), \n",
      "            maximum=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    target_pose: BoundedTensorSpec(\n",
      "        shape=torch.Size([6]),\n",
      "        space=ContinuousBox(\n",
      "            minimum=Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float32, contiguous=True), \n",
      "            maximum=Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    params: CompositeSpec(\n",
      "        max_theta_deltas: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([1]),\n",
      "            space=ContinuousBox(\n",
      "                minimum=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True), \n",
      "                maximum=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))\n",
      "reward_spec: UnboundedContinuousTensorSpec(\n",
      "    shape=torch.Size([1]),\n",
      "    space=ContinuousBox(\n",
      "        minimum=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True), \n",
      "        maximum=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "    device=cpu,\n",
      "    dtype=torch.float32,\n",
      "    domain=continuous)\n"
     ]
    }
   ],
   "source": [
    "print(\"observation_spec:\", env.observation_spec)\n",
    "print(\"state_spec:\", env.state_spec)\n",
    "print(\"reward_spec:\", env.reward_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute a couple of commands too to check that the output structure\n",
    "matches what is expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset tensordict TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                max_theta_deltas: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        target_pose: Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_cos: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_sin: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.reset()\n",
    "print(\"reset tensordict\", td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the :func:`env.rand_step` to generate\n",
    "an action randomly from the ``action_spec`` domain. A tensordict containing\n",
    "the hyperparams and the current state **must** be passed since our\n",
    "environment is stateless. In stateful contexts, ``env.rand_step()`` works\n",
    "perfectly too.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random step tensordict TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        max_theta_deltas: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                target_pose: Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thetas_cos: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thetas_sin: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                max_theta_deltas: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        target_pose: Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_cos: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_sin: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.rand_step(td)\n",
    "print(\"random step tensordict\", td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_and_error_pose(thetas, target_pose, open_chain):\n",
    "    open_chain = open_chain.to(thetas.device)\n",
    "    error_pose = compute_error_pose(open_chain, thetas, target_pose)\n",
    "    transformation = open_chain.forward_transformation(thetas)\n",
    "    pose = transforms.se3_log_map(transformation.get_matrix())\n",
    "    return pose, error_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "transformed_env = TransformedEnv(\n",
    "    env,\n",
    "    # Unsqueezes the observations that we will concatenate\n",
    "    UnsqueezeTransform(\n",
    "        unsqueeze_dim=0,\n",
    "        in_keys=[\"thetas\", \"target_pose\"],\n",
    "        in_keys_inv=[\"thetas\", \"target_pose\"],\n",
    "    ),\n",
    ")\n",
    "'''\n",
    "transformed_env = TransformedEnv(env)\n",
    "class OnManifodErrorTransform(Transform):\n",
    "    def __init__(self, in_keys, out_keys, open_chain):\n",
    "        super().__init__(in_keys, out_keys)\n",
    "        self.open_chain = open_chain\n",
    "        \n",
    "    def _apply_transform(self, obs: torch.Tensor) -> None:\n",
    "        #print(\"-----------------\")\n",
    "        #print(\"obs.shape\", obs.shape)\n",
    "        #print(\"obs\", obs)\n",
    "        thetas_sin, thetas_cos, target_pose = None, None, None\n",
    "        if len(obs.shape) == 1:\n",
    "            target_pose = obs[:-thetas_count*2].unsqueeze(0)\n",
    "            thetas_cos = obs[obs.shape[0] - (thetas_count*2):obs.shape[0] - (thetas_count*2)+1].unsqueeze(0)\n",
    "            thetas_sin = obs[obs.shape[0] - (thetas_count*2)+1:obs.shape[0]- (thetas_count*2)+2].unsqueeze(0)            \n",
    "        elif len(obs.shape) == 2:\n",
    "            target_pose = obs[:,:-thetas_count*2]\n",
    "            thetas_cos = obs[:,obs.shape[1] - (thetas_count*2):obs.shape[1] - (thetas_count*2)+1]\n",
    "            thetas_sin = obs[:,obs.shape[1] - (thetas_count*2)+1:obs.shape[1]- (thetas_count*2)+2]\n",
    "        #print(thetas_cos)\n",
    "        #print(thetas_sin)\n",
    "        #print(\"thetas.shape\", thetas.shape)\n",
    "        #print(\"target_pose.shape\", target_pose.shape)\n",
    "        thetas = torch.atan2(thetas_sin, thetas_cos)\n",
    "        #print(thetas)\n",
    "        pose, error_pose = get_pose_and_error_pose(thetas, target_pose, self.open_chain)\n",
    "        # pose decomposition\n",
    "        #pose_linear =  pose[:, :3]\n",
    "        #pose_angular_cos =  pose[:, 3:].cos()\n",
    "        #pose_angular_sin =  pose[:, 3:].sin()\n",
    "        # error pose decomposition \n",
    "        error_pose_linear =  error_pose[:, :3]\n",
    "        error_pose_angular_cos =  error_pose[:, 3:].cos()\n",
    "        error_pose_angular_sin =  error_pose[:, 3:].sin()\n",
    "        \n",
    "        #print(\"---------------------\")\n",
    "        #print(\"obs\", obs)\n",
    "        #print(\"error_pose\", error_pose)\n",
    "        #print(\"pose\", pose)\n",
    "        #print(\"target_pose\", target_pose)\n",
    "        #print(\"---------------------\")\n",
    "        \n",
    "        #manifold_error = torch.cat([pose_linear, pose_angular_cos, pose_angular_sin, error_pose_linear, error_pose_angular_cos, error_pose_angular_sin, thetas_sin, thetas_cos], 1)\n",
    "        manifold_error = torch.cat([error_pose[:,5:6]], 1)        \n",
    "        #print(\"manifold_error\", manifold_error)\n",
    "        #print(\"obs\", obs.shape, manifold_error.shape)\n",
    "        if len(obs.shape) == 1:\n",
    "            return manifold_error.squeeze(0)\n",
    "        else:\n",
    "            #print(\"---------------------\")\n",
    "            #print(\"error_pose\", error_pose.abs()[:, :])\n",
    "            #print(\"error_pose max\", error_pose[:,-1].max().item())\n",
    "            #print(\"error_pose min\", error_pose[:,-1].min().item())\n",
    "            #print(\"---------------------\")\n",
    "            return manifold_error\n",
    "\n",
    "    # _apply_to_composite will execute the observation spec transform across all\n",
    "    # in_keys/out_keys pairs and write the result in the observation_spec which\n",
    "    # is of type ``Composite``\n",
    "        \n",
    "    #TODO minimum and maximum are incorrect!!\n",
    "    @_apply_to_composite\n",
    "    def transform_observation_spec(self, observation_spec):\n",
    "        return BoundedTensorSpec(\n",
    "            minimum=-10000,\n",
    "            maximum=10000,\n",
    "            shape=(1),\n",
    "            dtype=observation_spec.dtype,\n",
    "            device=observation_spec.device,\n",
    "        )\n",
    "        \n",
    "cat_transform = CatTensors(\n",
    "    in_keys=[\"thetas_sin\", \"thetas_cos\", \"target_pose\"], dim=-1, out_key=\"observation\", del_keys=False\n",
    ")\n",
    "transformed_env.append_transform(cat_transform)\n",
    "on_manifold_error = OnManifodErrorTransform(in_keys=[\"observation\"], \n",
    "                                            out_keys=[\"on_manifold_error\"],\n",
    "                                            open_chain=used_open_chain)\n",
    "transformed_env.append_transform(on_manifold_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#cat_transform = CatTensors(\n",
    "#    in_keys=[\"sin\", \"cos\", \"thdot\"], dim=-1, out_key=\"observation\", del_keys=False\n",
    "#)\n",
    "#transformed_env.append_transform(cat_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, let us check that our env specs match what is received:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(transformed_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing a rollout\n",
    "\n",
    "Executing a rollout is a succession of simple steps:\n",
    "\n",
    "* reset the environment\n",
    "* while some condition is not met:\n",
    "\n",
    "  * compute an action given a policy\n",
    "  * execute a step given this action\n",
    "  * collect the data\n",
    "  * make a MDP step\n",
    "\n",
    "* gather the data and return\n",
    "\n",
    "These operations have been convinently wrapped in the :func:`EnvBase.rollout`\n",
    "method, from which we provide a simplified version here below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data from rollout: TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([100, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([100, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                on_manifold_error: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        max_theta_deltas: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([100]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                target_pose: Tensor(shape=torch.Size([100, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thetas_cos: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thetas_sin: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([100]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([100, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        on_manifold_error: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                max_theta_deltas: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([100]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        target_pose: Tensor(shape=torch.Size([100, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_cos: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_sin: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([100]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "def simple_rollout(steps=100):\n",
    "    # preallocate:\n",
    "    data = TensorDict({}, [steps])\n",
    "    # reset\n",
    "    _data = transformed_env.reset()\n",
    "    for i in range(steps):\n",
    "        _data[\"action\"] = transformed_env.action_spec.rand()\n",
    "        _data = transformed_env.step(_data)\n",
    "        data[i] = _data\n",
    "        _data = step_mdp(_data, keep_other=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "print(\"data from rollout:\", simple_rollout(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching computations\n",
    "\n",
    "The last unexplored end of our tutorial is the ability that we have to\n",
    "batch computations in TorchRL. Because our environment does not\n",
    "make any assumptions regarding the input data shape, we can seamlessly\n",
    "execute it over batches of data. Even better: for non-batch-locked\n",
    "environments such as our Pendulum, we can change the batch size on the fly\n",
    "without recreating the env.\n",
    "To do this, we just generate parameters with the desired shape.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset (batch size of 10) TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        on_manifold_error: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                max_theta_deltas: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        target_pose: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_cos: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_sin: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "rand step (batch size of 10) TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                on_manifold_error: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        max_theta_deltas: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([10]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                target_pose: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thetas_cos: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thetas_sin: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        on_manifold_error: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                max_theta_deltas: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        target_pose: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_cos: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_sin: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10  # number of environments to be executed in batch\n",
    "td = transformed_env.reset(transformed_env.gen_params(batch_size=[batch_size]))\n",
    "print(f\"reset (batch size of {batch_size})\", td)\n",
    "td = transformed_env.rand_step(td)\n",
    "print(f\"rand step (batch size of {batch_size})\", td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "executing a rollout with a batch of data requires us to reset the env\n",
    "out of the rollout function, since we need to define the batch_size\n",
    "dynamically and this is not supported by :func:`EnvBase.rollout`:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout of len 3 (batch size of 10): TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                on_manifold_error: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        max_theta_deltas: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([10, 3]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                target_pose: Tensor(shape=torch.Size([10, 3, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thetas_cos: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thetas_sin: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10, 3]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        on_manifold_error: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                max_theta_deltas: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10, 3]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        target_pose: Tensor(shape=torch.Size([10, 3, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_cos: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas_sin: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([10, 3]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "rollout = transformed_env.rollout(\n",
    "    3,\n",
    "    auto_reset=False,  # we're executing the reset out of the ``rollout`` call\n",
    "    tensordict=transformed_env.reset(transformed_env.gen_params(batch_size=[batch_size])),\n",
    ")\n",
    "print(\"rollout of len 3 (batch size of 10):\", rollout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a simple policy\n",
    "\n",
    "In this example, we will train a simple policy using the reward as a\n",
    "differentiable objective (i.e. a negative loss).\n",
    "We will take advantage of the fact that our dynamic system is fully\n",
    "differentiable to backpropagate through the trajectory return and adjust the\n",
    "weights of our policy to maximise this value directly. Of course, in many\n",
    "settings many of the assumptions we make do not hold, such as\n",
    "differentiability of the system and full access to the underlying mechanics.\n",
    "\n",
    "Still, this is a very simple example that showcases how a training loop can\n",
    "be coded with a custom environment in TorchRL.\n",
    "\n",
    "Let us first write the policy network:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "transformed_env.set_seed(0)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(in_features=1, out_features=4, bias=True),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(in_features=4, out_features=thetas_count, bias=True)\n",
    ").cuda()\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DummyActor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super(DummyActor, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=1, out_features=64, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=64, bias=True)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=64, bias=True)\n",
    "        self.fc4 = nn.Linear(in_features=64, out_features=1, bias=True)\n",
    "        self.fc5 = nn.Linear(in_features=64, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.tanh(self.fc1(state))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        cos = self.fc4(x).cos()\n",
    "        sin = self.fc5(x).sin()\n",
    "        return torch.cat([sin, cos], 1)\n",
    "\n",
    "net = DummyActor().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and our optimizer:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "We will successively:\n",
    "\n",
    "* generate a trajectory\n",
    "* sum the rewards\n",
    "* backpropagate through the graph defined by these operations\n",
    "* clip the gradient norm and make an optimization step\n",
    "* repeat\n",
    "\n",
    "At the end of the training loop, we should have a final reward close to 0\n",
    "which demonstrates that the pendulum is upward and still as desired.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward: -0.0953, last reward: -0.0003, gradient norm:  2.421:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 570/625 [03:46<00:23,  2.36it/s]"
     ]
    }
   ],
   "source": [
    "policy = TensorDictModule(\n",
    "    net,\n",
    "    in_keys=[\"on_manifold_error\"], #[\"target_pose\"],\n",
    "    out_keys=[\"action\"],\n",
    ").cuda()\n",
    "optim = torch.optim.Adam(policy.parameters(), lr=2e-5)\n",
    "\n",
    "batch_size = 32\n",
    "iterations = 20_000\n",
    "pbar = tqdm.tqdm(range(iterations // batch_size))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, iterations)\n",
    "logs = defaultdict(list)\n",
    "\n",
    "# current_env = env \n",
    "current_env = transformed_env.cuda()\n",
    "for _ in pbar:\n",
    "    init_td = current_env.reset(current_env.gen_params(batch_size=[batch_size])).cuda()\n",
    "    rollout = current_env.rollout(10, policy, tensordict=init_td, auto_reset=False).cuda()\n",
    "    #print(rollout)\n",
    "    traj_return = rollout[\"next\", \"reward\"].mean()\n",
    "    (-traj_return).backward()\n",
    "    gn = torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    pbar.set_description(\n",
    "        f\"reward: {traj_return: 4.4f}, \"\n",
    "        f\"last reward: {rollout[..., -1]['next', 'reward'].mean(): 4.4f}, gradient norm: {gn: 4.4}\"\n",
    "    )\n",
    "    logs[\"return\"].append(traj_return.item())\n",
    "    logs[\"last_reward\"].append(rollout[..., -1][\"next\", \"reward\"].mean().item())\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "def plot():\n",
    "    import matplotlib\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    is_ipython = \"inline\" in matplotlib.get_backend()\n",
    "    if is_ipython:\n",
    "        from IPython import display\n",
    "\n",
    "    with plt.ion():\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(logs[\"return\"])\n",
    "        plt.title(\"returns\")\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(logs[\"last_reward\"])\n",
    "        plt.title(\"last reward\")\n",
    "        plt.xlabel(\"iteration\")\n",
    "        if is_ipython:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.parameter.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
