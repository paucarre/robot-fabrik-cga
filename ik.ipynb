{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.tensordict import TensorDict, TensorDictBase\n",
    "from torch import nn\n",
    "\n",
    "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec\n",
    "from torchrl.envs import (\n",
    "    CatTensors,\n",
    "    EnvBase,\n",
    "    Transform,\n",
    "    TransformedEnv,\n",
    "    UnsqueezeTransform,\n",
    ")\n",
    "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
    "from torchrl.envs.utils import check_env_specs, step_mdp\n",
    "\n",
    "DEFAULT_X = np.pi\n",
    "DEFAULT_Y = 1.0\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas_count = 6\n",
    "pose_count = 6\n",
    "error_done_threshold = 1e-3\n",
    "weights = torch.Tensor([1.0, 0.0, 0.0, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from pytorch3d import transforms\n",
    "import math\n",
    "from linguamechanica.kinematics import DifferentiableOpenChainMechanism\n",
    "from linguamechanica.kinematics import UrdfRobotLibrary\n",
    "\n",
    "urdf_robot = UrdfRobotLibrary.dobot_cr5()\n",
    "open_chain = urdf_robot.extract_open_chains(0.3)[-1]\n",
    "\n",
    "def force_parameters_within_bounds(thetas):\n",
    "    bigger_than_pi = thetas > math.pi\n",
    "    thetas[bigger_than_pi] = thetas[bigger_than_pi] - (2.0 * math.pi)\n",
    "    less_than_minus_pi = thetas < -math.pi\n",
    "    thetas[less_than_minus_pi] = thetas[less_than_minus_pi] + (2.0 * math.pi)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reward(thetas, target_pose, weights, error_done_threshold):\n",
    "    if len(thetas.shape) == 1:\n",
    "        thetas = thetas.unsqueeze(0)\n",
    "    if len(target_pose.shape) == 1:\n",
    "        target_pose = target_pose.unsqueeze(0)\n",
    "    error_pose = open_chain.compute_error_pose(\n",
    "        thetas, target_pose\n",
    "    )\n",
    "    pose_error = DifferentiableOpenChainMechanism.compute_weighted_error(\n",
    "        error_pose, weights\n",
    "    )\n",
    "    done = pose_error < error_done_threshold\n",
    "    reward = - pose_error\n",
    "    return reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def _step(tensordict):\n",
    "    thetas = tensordict[\"thetas\"]\n",
    "    theta_deltas = tensordict[\"action\"]\n",
    "    max_theta_deltas = tensordict[\"params\", \"max_theta_deltas\"]\n",
    "    if len(thetas.shape) == 1:\n",
    "        max_theta_deltas = max_theta_deltas.unsqueeze(1)\n",
    "    theta_deltas = theta_deltas.clamp(-max_theta_deltas, max_theta_deltas)\n",
    "    new_thetas = thetas - theta_deltas\n",
    "    target_pose = tensordict[\"target_pose\"]\n",
    "    #TODO: I have no idea if this is a good idea or not\n",
    "    new_thetas = force_parameters_within_bounds(new_thetas)\n",
    "    reward, done = compute_reward(new_thetas, target_pose, weights, error_done_threshold)\n",
    "    out = TensorDict(\n",
    "        {\n",
    "            \"next\": {\n",
    "                \"thetas\": new_thetas,\n",
    "                \"target_pose\": target_pose,\n",
    "                \"params\": tensordict[\"params\"],\n",
    "                \"reward\": reward,\n",
    "                \"done\": done,\n",
    "            }\n",
    "        },\n",
    "        tensordict.shape,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniformly_sample_parameters_within_constraints(open_chain, batch_size):\n",
    "    samples = []\n",
    "    for sample_idx in range(batch_size):\n",
    "        coordinates = []\n",
    "        for i in range(len(open_chain.joint_limits)):\n",
    "            # TODO: check if unconstrained works\n",
    "            coordinates.append(\n",
    "                random.uniform(\n",
    "                    open_chain.joint_limits[i][0],\n",
    "                    open_chain.joint_limits[i][1],\n",
    "                )\n",
    "            )\n",
    "        samples.append(torch.Tensor(coordinates).unsqueeze(0))\n",
    "    return torch.cat(samples, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_target_pose(target_thetas):\n",
    "    if len(target_thetas.shape) == 1:\n",
    "        target_thetas = target_thetas.unsqueeze(0)\n",
    "    target_transformation = open_chain.forward_transformation(\n",
    "        target_thetas\n",
    "    )\n",
    "    target_pose = transforms.se3_log_map(\n",
    "        target_transformation.get_matrix()\n",
    "    )\n",
    "    if target_thetas.shape[0] == 1:\n",
    "        target_thetas = target_thetas.squeeze(0)\n",
    "    return target_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def _reset(self, tensordict):\n",
    "    if tensordict is None or tensordict.is_empty():\n",
    "        # if no tensordict is passed, we generate a single set of hyperparameters\n",
    "        # Otherwise, we assume that the input tensordict contains all the relevant\n",
    "        # parameters to get started.\n",
    "        tensordict = self.gen_params(batch_size=self.batch_size)\n",
    "    batch_size = 1 if len(tensordict.shape) == 0 else tensordict.shape[0]\n",
    "    thetas = uniformly_sample_parameters_within_constraints(open_chain, batch_size).to(device=self.device)\n",
    "    if batch_size == 1:\n",
    "        thetas = thetas.squeeze(0)\n",
    "    thetas = force_parameters_within_bounds(thetas)\n",
    "    #TODO: randommize this better\n",
    "    target_thetas = thetas + torch.randn(thetas.shape)\n",
    "    target_thetas = force_parameters_within_bounds(target_thetas)\n",
    "    target_pose =  generate_random_target_pose(target_thetas)\n",
    "    #TODO: finish this\n",
    "    target_pose = (\n",
    "        torch.rand([*tensordict.shape, pose_count], generator=self.rng, device=self.device)\n",
    "    )\n",
    "    out = TensorDict(\n",
    "        {\n",
    "            \"thetas\": thetas,\n",
    "            \"target_pose\": target_pose,\n",
    "            \"params\": tensordict[\"params\"],\n",
    "        },\n",
    "        batch_size=tensordict.shape,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def _make_spec(self, td_params):\n",
    "    # Under the hood, this will populate self.output_spec[\"observation\"]\n",
    "    self.observation_spec = CompositeSpec(\n",
    "        thetas=BoundedTensorSpec(\n",
    "            minimum=-torch.ones(thetas_count) * torch.pi,\n",
    "            maximum= torch.ones(thetas_count) * torch.pi,\n",
    "            shape=(thetas_count),\n",
    "            dtype=torch.float32,\n",
    "        ),\n",
    "        #TODO: bounds are wrong\n",
    "        target_pose=BoundedTensorSpec(\n",
    "            minimum=-torch.ones(thetas_count) * torch.pi,\n",
    "            maximum= torch.ones(thetas_count) * torch.pi,\n",
    "            shape=(pose_count),\n",
    "            dtype=torch.float32,\n",
    "        ),\n",
    "        # we need to add the \"params\" to the observation specs, as we want\n",
    "        # to pass it at each step during a rollout\n",
    "        params=make_composite_from_td(td_params[\"params\"]),\n",
    "        shape=(),\n",
    "    )\n",
    "    # since the environment is stateless, we expect the previous output as input.\n",
    "    # For this, EnvBase expects some state_spec to be available\n",
    "    self.state_spec = self.observation_spec.clone()\n",
    "    # action-spec will be automatically wrapped in input_spec when\n",
    "    # `self.action_spec = spec` will be called supported\n",
    "    self.action_spec = BoundedTensorSpec(\n",
    "        minimum=-td_params[\"params\", \"max_theta_deltas\"],\n",
    "        maximum=td_params[\"params\", \"max_theta_deltas\"],\n",
    "        shape=(thetas_count,),\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "    self.reward_spec = UnboundedContinuousTensorSpec(shape=(*td_params.shape, 1))\n",
    "\n",
    "\n",
    "def make_composite_from_td(td):\n",
    "    # custom funtion to convert a tensordict in a similar spec structure\n",
    "    # of unbounded values.\n",
    "    composite = CompositeSpec(\n",
    "        {\n",
    "            key: make_composite_from_td(tensor)\n",
    "            if isinstance(tensor, TensorDictBase)\n",
    "            else UnboundedContinuousTensorSpec(\n",
    "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
    "            )\n",
    "            for key, tensor in td.items()\n",
    "        },\n",
    "        shape=td.shape,\n",
    "    )\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def _set_seed(self, seed: Optional[int]):\n",
    "    rng = torch.manual_seed(seed)\n",
    "    self.rng = rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def gen_params(g=10.0, batch_size=None) -> TensorDictBase:\n",
    "    \"\"\"Returns a tensordict containing the physical parameters such as gravitational force and torque or speed limits.\"\"\"\n",
    "    if batch_size is None:\n",
    "        batch_size = []\n",
    "    td = TensorDict(\n",
    "        {\n",
    "            \"params\": TensorDict(\n",
    "                {\n",
    "                    \"max_theta_deltas\": 0.1,\n",
    "                },\n",
    "                [],\n",
    "            )\n",
    "        },\n",
    "        [],\n",
    "    )\n",
    "    if batch_size:\n",
    "        td = td.expand(batch_size).contiguous()\n",
    "    return td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class PendulumEnv(EnvBase):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 30,\n",
    "    }\n",
    "    batch_locked = False\n",
    "\n",
    "    def __init__(self, td_params=None, seed=None, device=\"cpu\"):\n",
    "        if td_params is None:\n",
    "            td_params = self.gen_params()\n",
    "\n",
    "        super().__init__(device=device, batch_size=[])\n",
    "        self._make_spec(td_params)\n",
    "        if seed is None:\n",
    "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
    "        self.set_seed(seed)\n",
    "\n",
    "    # Helpers: _make_step and gen_params\n",
    "    gen_params = staticmethod(gen_params)\n",
    "    _make_spec = _make_spec\n",
    "\n",
    "    # Mandatory methods: _step, _reset and _set_seed\n",
    "    _reset = _reset\n",
    "    _step = staticmethod(_step)\n",
    "    _set_seed = _set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "env = PendulumEnv()\n",
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at our specs to have a visual representation of the environment\n",
    "signature:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"observation_spec:\", env.observation_spec)\n",
    "print(\"state_spec:\", env.state_spec)\n",
    "print(\"reward_spec:\", env.reward_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute a couple of commands too to check that the output structure\n",
    "matches what is expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_transformation torch.Size([6, 6]) torch.Size([1, 6, 1])\n",
      "reset tensordict TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                max_theta_deltas: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        target_pose: Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas: Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.reset()\n",
    "print(\"reset tensordict\", td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the :func:`env.rand_step` to generate\n",
    "an action randomly from the ``action_spec`` domain. A tensordict containing\n",
    "the hyperparams and the current state **must** be passed since our\n",
    "environment is stateless. In stateful contexts, ``env.rand_step()`` works\n",
    "perfectly too.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stuff\n",
      "torch.Size([10, 6]) torch.Size([10, 6]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000])\n",
      "compute_error_pose torch.Size([10, 6]) torch.Size([10, 6])\n",
      "forward_transformation torch.Size([6, 6]) torch.Size([10, 6, 1])\n",
      "random step tensordict TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        max_theta_deltas: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([10]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                target_pose: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thetas: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                max_theta_deltas: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        target_pose: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.rand_step(td)\n",
    "print(\"random step tensordict\", td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming an environment\n",
    "\n",
    "Writing environment transforms for stateless simulators is slightly more\n",
    "complicated than for stateful ones: transforming an output entry that needs\n",
    "to be read at the following iteration requires to apply the inverse transform\n",
    "before calling :func:`env.step` at the next step.\n",
    "This is an ideal scenario to showcase all the features of torchrl's\n",
    "transforms!\n",
    "\n",
    "For instance, in the following transformed environment we unsqueeze the entries\n",
    "``[\"th\", \"thdot\"]`` to be able to stack them along the last\n",
    "dimension. We also pass them as ``in_keys_inv`` to squeeze them back to their\n",
    "original shape once they are passed as input in the next iteration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transformed_env = TransformedEnv(\n",
    "    env,\n",
    "    # Unsqueezes the observations that we will concatenate\n",
    "    UnsqueezeTransform(\n",
    "        unsqueeze_dim=-1,\n",
    "        in_keys=[\"thetas\"],\n",
    "        in_keys_inv=[\"thetas\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing custom transforms\n",
    "\n",
    "TorchRL's transforms may not cover all the operations one wants to execute\n",
    "after an environment has been executed.\n",
    "Writing a transform does not require much effort. As for the environment\n",
    "design, there are two steps in writing a transform:\n",
    "\n",
    "- Getting the dynamics right (forward and inverse);\n",
    "- Adapting the environment specs.\n",
    "\n",
    "A transform can be used in two settings: on its own, it can be used as a\n",
    ":class:`torch.nn.Module`. It can also be used appended to a\n",
    ":class:`~torchrl.envs.TransformedEnv`. The structure of the class allows to\n",
    "customize the behaviour in the different contexts.\n",
    "\n",
    "A :class:`~torchrl.envs.Transform` skeleton can be summarized as follows:\n",
    "\n",
    "```\n",
    "class Transform(nn.Module):\n",
    "    def forward(self, tensordict):\n",
    "    def _apply_transform(self, tensordict):\n",
    "    def _step(self, tensordict):\n",
    "    def _call(self, tensordict):\n",
    "    def inv(self, tensordict):\n",
    "    def _inv_apply_transform(self, tensordict):\n",
    "```\n",
    "There are three entry points (:func:`forward`, :func:`_step` and :func:`inv`)\n",
    "which all receive :class:`tensordict.TensorDict` instances. The first two\n",
    "will eventually go through the keys indicated by :obj:`Transform.in_keys`\n",
    "and call :func:`Transform._apply_transform` to each of these. The results will\n",
    "be written in the entries pointed by :obj:`Transform.out_keys` if provided\n",
    "(if not the ``in_keys`` will be updated with the transformed values).\n",
    "If inverse transforms need to be executed, a similar data flow will be\n",
    "executed but with the :func:`Transform.inv` and\n",
    ":func:`Transform._inv_apply_transform` methods and across the ``in_keys_inv``\n",
    "and ``out_keys_inv`` list of keys.\n",
    "The following figure summarized this flow for environments and replay\n",
    "buffers.\n",
    "\n",
    ".. figure:: /_static/img/transforms.png\n",
    "\n",
    "   Transform API\n",
    "\n",
    "In some cases, a transform will not work on a subset of keys in a unitary\n",
    "manner, but will execute some operation on the parent environment or\n",
    "work with the entire input tensordict.\n",
    "In those cases, the :func:`_call` and :func:`forward` methods should be\n",
    "re-written, and the :func:`_apply_transform` method can be skipped.\n",
    "\n",
    "Let us code new transforms that will compute the ``sine`` and ``cosine``\n",
    "values of the position angle, as these values are more useful to us to learn\n",
    "a policy than the raw angle value:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PendulumEnv' object has no attribute 'append_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m t_sin \u001b[38;5;241m=\u001b[39m SinTransform(in_keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mth\u001b[39m\u001b[38;5;124m\"\u001b[39m], out_keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     38\u001b[0m t_cos \u001b[38;5;241m=\u001b[39m CosTransform(in_keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mth\u001b[39m\u001b[38;5;124m\"\u001b[39m], out_keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 39\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_transform\u001b[49m(t_sin)\n\u001b[1;32m     40\u001b[0m env\u001b[38;5;241m.\u001b[39mappend_transform(t_cos)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PendulumEnv' object has no attribute 'append_transform'"
     ]
    }
   ],
   "source": [
    "class SinTransform(Transform):\n",
    "    def _apply_transform(self, obs: torch.Tensor) -> None:\n",
    "        return obs.sin()\n",
    "\n",
    "    # _apply_to_composite will execute the observation spec transform across all\n",
    "    # in_keys/out_keys pairs and write the result in the observation_spec which\n",
    "    # is of type ``Composite``\n",
    "    @_apply_to_composite\n",
    "    def transform_observation_spec(self, observation_spec):\n",
    "        return BoundedTensorSpec(\n",
    "            minimum=-1,\n",
    "            maximum=1,\n",
    "            shape=observation_spec.shape,\n",
    "            dtype=observation_spec.dtype,\n",
    "            device=observation_spec.device,\n",
    "        )\n",
    "\n",
    "\n",
    "class CosTransform(Transform):\n",
    "    def _apply_transform(self, obs: torch.Tensor) -> None:\n",
    "        return obs.cos()\n",
    "\n",
    "    # _apply_to_composite will execute the observation spec transform across all\n",
    "    # in_keys/out_keys pairs and write the result in the observation_spec which\n",
    "    # is of type ``Composite``\n",
    "    @_apply_to_composite\n",
    "    def transform_observation_spec(self, observation_spec):\n",
    "        return BoundedTensorSpec(\n",
    "            minimum=-1,\n",
    "            maximum=1,\n",
    "            shape=observation_spec.shape,\n",
    "            dtype=observation_spec.dtype,\n",
    "            device=observation_spec.device,\n",
    "        )\n",
    "\n",
    "\n",
    "t_sin = SinTransform(in_keys=[\"th\"], out_keys=[\"sin\"])\n",
    "t_cos = CosTransform(in_keys=[\"th\"], out_keys=[\"cos\"])\n",
    "env.append_transform(t_sin)\n",
    "env.append_transform(t_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnManifodError(Transform):\n",
    "    def _apply_transform(self, obs: torch.Tensor) -> None:\n",
    "        return obs.sin()\n",
    "\n",
    "    # _apply_to_composite will execute the observation spec transform across all\n",
    "    # in_keys/out_keys pairs and write the result in the observation_spec which\n",
    "    # is of type ``Composite``\n",
    "    @_apply_to_composite\n",
    "    def transform_observation_spec(self, observation_spec):\n",
    "        return BoundedTensorSpec(\n",
    "            minimum=-1,\n",
    "            maximum=1,\n",
    "            shape=observation_spec.shape,\n",
    "            dtype=observation_spec.dtype,\n",
    "            device=observation_spec.device,\n",
    "        )\n",
    "\n",
    "\n",
    "class CosTransform(Transform):\n",
    "    def _apply_transform(self, obs: torch.Tensor) -> None:\n",
    "        return obs.cos()\n",
    "\n",
    "    # _apply_to_composite will execute the observation spec transform across all\n",
    "    # in_keys/out_keys pairs and write the result in the observation_spec which\n",
    "    # is of type ``Composite``\n",
    "    @_apply_to_composite\n",
    "    def transform_observation_spec(self, observation_spec):\n",
    "        return BoundedTensorSpec(\n",
    "            minimum=-1,\n",
    "            maximum=1,\n",
    "            shape=observation_spec.shape,\n",
    "            dtype=observation_spec.dtype,\n",
    "            device=observation_spec.device,\n",
    "        )\n",
    "\n",
    "\n",
    "t_sin = SinTransform(in_keys=[\"th\"], out_keys=[\"sin\"])\n",
    "t_cos = CosTransform(in_keys=[\"th\"], out_keys=[\"cos\"])\n",
    "env.append_transform(t_sin)\n",
    "env.append_transform(t_cos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenates the observations onto an \"observation\" entry.\n",
    "del_keys=False ensures that we keep these values for the next\n",
    "iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cat_transform = CatTensors(\n",
    "    in_keys=[\"sin\", \"cos\", \"thdot\"], dim=-1, out_key=\"observation\", del_keys=False\n",
    ")\n",
    "transformed_env.append_transform(cat_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, let us check that our env specs match what is received:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "CatTensor got a list of keys that does not match the keys in observation_spec. Make sure the environment has an observation_spec attribute that includes all the specs needed for CatTensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[189], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcheck_env_specs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_env\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torchrl/envs/utils.py:399\u001b[0m, in \u001b[0;36mcheck_env_specs\u001b[0;34m(env, return_contiguous, check_dtype, seed)\u001b[0m\n\u001b[1;32m    396\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m    397\u001b[0m env\u001b[38;5;241m.\u001b[39mset_seed(seed)\n\u001b[0;32m--> 399\u001b[0m fake_tensordict \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_tensordict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m real_tensordict \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrollout(\u001b[38;5;241m3\u001b[39m, return_contiguous\u001b[38;5;241m=\u001b[39mreturn_contiguous)\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_contiguous:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torchrl/envs/common.py:1307\u001b[0m, in \u001b[0;36mEnvBase.fake_tensordict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a fake tensordict with key-value pairs that match in shape, device and dtype what can be expected during an environment rollout.\"\"\"\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m state_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_spec\n\u001b[0;32m-> 1307\u001b[0m observation_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_spec\u001b[49m\n\u001b[1;32m   1308\u001b[0m action_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_action_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;66;03m# instantiates reward_spec if needed\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torchrl/envs/transforms/transforms.py:610\u001b[0m, in \u001b[0;36mTransformedEnv.observation_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobservation_spec\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorSpec:\n\u001b[1;32m    609\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Observation spec of the transformed environment.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 610\u001b[0m     observation_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_spec\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_observation_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observation_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    612\u001b[0m         observation_spec \u001b[38;5;241m=\u001b[39m CompositeSpec(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torchrl/envs/transforms/transforms.py:575\u001b[0m, in \u001b[0;36mTransformedEnv.output_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    573\u001b[0m output_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_env\u001b[38;5;241m.\u001b[39moutput_spec\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    574\u001b[0m output_spec\u001b[38;5;241m.\u001b[39munlock_()\n\u001b[0;32m--> 575\u001b[0m output_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_output_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m output_spec\u001b[38;5;241m.\u001b[39mlock_()\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_specs:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torchrl/envs/transforms/transforms.py:866\u001b[0m, in \u001b[0;36mCompose.transform_output_spec\u001b[0;34m(self, output_spec)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_output_spec\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_spec: TensorSpec) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorSpec:\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m--> 866\u001b[0m         output_spec \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_output_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_spec\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torchrl/envs/transforms/transforms.py:286\u001b[0m, in \u001b[0;36mTransform.transform_output_spec\u001b[0;34m(self, output_spec)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transforms the output spec such that the resulting spec matches transform mapping.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mThis method should generally be left untouched. Changes should be implemented using\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    285\u001b[0m output_spec \u001b[38;5;241m=\u001b[39m output_spec\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m--> 286\u001b[0m output_spec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_observation_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_observation_spec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_spec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_observation_spec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_reward_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output_spec\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    290\u001b[0m     output_spec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_reward_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_reward_spec(\n\u001b[1;32m    291\u001b[0m         output_spec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_reward_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    292\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torchrl/envs/transforms/transforms.py:2562\u001b[0m, in \u001b[0;36mCatTensors.transform_observation_spec\u001b[0;34m(self, observation_spec)\u001b[0m\n\u001b[1;32m   2554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCatTensor cannot infer the output observation spec as there are multiple input keys but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly one observation_spec.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2557\u001b[0m     )\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation_spec, CompositeSpec) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m   2560\u001b[0m     [key \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m observation_spec\u001b[38;5;241m.\u001b[39mkeys(\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[1;32m   2561\u001b[0m ):\n\u001b[0;32m-> 2562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2563\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCatTensor got a list of keys that does not match the keys in observation_spec. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure the environment has an observation_spec attribute that includes all the specs needed for CatTensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2565\u001b[0m     )\n\u001b[1;32m   2567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation_spec, CompositeSpec):\n\u001b[1;32m   2568\u001b[0m     \u001b[38;5;66;03m# by def, there must be only one key\u001b[39;00m\n\u001b[1;32m   2569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m observation_spec\n",
      "\u001b[0;31mValueError\u001b[0m: CatTensor got a list of keys that does not match the keys in observation_spec. Make sure the environment has an observation_spec attribute that includes all the specs needed for CatTensor."
     ]
    }
   ],
   "source": [
    "check_env_specs(transformed_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing a rollout\n",
    "\n",
    "Executing a rollout is a succession of simple steps:\n",
    "\n",
    "* reset the environment\n",
    "* while some condition is not met:\n",
    "\n",
    "  * compute an action given a policy\n",
    "  * execute a step given this action\n",
    "  * collect the data\n",
    "  * make a MDP step\n",
    "\n",
    "* gather the data and return\n",
    "\n",
    "These operations have been convinently wrapped in the :func:`EnvBase.rollout`\n",
    "method, from which we provide a simplified version here below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_transformation torch.Size([6, 6]) torch.Size([1, 6, 1])\n",
      "stuff\n",
      "torch.Size([6]) torch.Size([6]) tensor(0.1000)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[190], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m         _data \u001b[38;5;241m=\u001b[39m step_mdp(_data, keep_other\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata from rollout:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43msimple_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[190], line 8\u001b[0m, in \u001b[0;36msimple_rollout\u001b[0;34m(steps)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[1;32m      7\u001b[0m     _data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_spec\u001b[38;5;241m.\u001b[39mrand()\n\u001b[0;32m----> 8\u001b[0m     _data \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     data[i] \u001b[38;5;241m=\u001b[39m _data\n\u001b[1;32m     10\u001b[0m     _data \u001b[38;5;241m=\u001b[39m step_mdp(_data, keep_other\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torchrl/envs/common.py:822\u001b[0m, in \u001b[0;36mEnvBase.step\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# sanity check\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_tensordict_shape(tensordict)\n\u001b[0;32m--> 822\u001b[0m tensordict_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# this tensordict should contain a \"next\" key\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[174], line 6\u001b[0m, in \u001b[0;36m_step\u001b[0;34m(tensordict)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(thetas\u001b[38;5;241m.\u001b[39mshape, theta_deltas\u001b[38;5;241m.\u001b[39mshape, tensordict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_theta_deltas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m theta_deltas \u001b[38;5;241m=\u001b[39m theta_deltas\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m-\u001b[39m\u001b[43mtensordict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_theta_deltas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \n\u001b[1;32m      7\u001b[0m                                   tensordict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_theta_deltas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      8\u001b[0m new_thetas \u001b[38;5;241m=\u001b[39m thetas \u001b[38;5;241m-\u001b[39m theta_deltas\n\u001b[1;32m      9\u001b[0m target_pose \u001b[38;5;241m=\u001b[39m tensordict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_pose\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "def simple_rollout(steps=100):\n",
    "    # preallocate:\n",
    "    data = TensorDict({}, [steps])\n",
    "    # reset\n",
    "    _data = env.reset()\n",
    "    for i in range(steps):\n",
    "        _data[\"action\"] = env.action_spec.rand()\n",
    "        _data = env.step(_data)\n",
    "        data[i] = _data\n",
    "        _data = step_mdp(_data, keep_other=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "print(\"data from rollout:\", simple_rollout(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching computations\n",
    "\n",
    "The last unexplored end of our tutorial is the ability that we have to\n",
    "batch computations in TorchRL. Because our environment does not\n",
    "make any assumptions regarding the input data shape, we can seamlessly\n",
    "execute it over batches of data. Even better: for non-batch-locked\n",
    "environments such as our Pendulum, we can change the batch size on the fly\n",
    "without recreating the env.\n",
    "To do this, we just generate parameters with the desired shape.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_transformation torch.Size([6, 6]) torch.Size([10, 6, 1])\n",
      "reset (batch size of 10) TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                max_theta_deltas: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        target_pose: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "stuff\n",
      "torch.Size([10, 6]) torch.Size([10, 6]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000])\n",
      "compute_error_pose torch.Size([10, 6]) torch.Size([10, 6])\n",
      "forward_transformation torch.Size([6, 6]) torch.Size([10, 6, 1])\n",
      "rand step (batch size of 10) TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        max_theta_deltas: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([10]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                target_pose: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thetas: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                max_theta_deltas: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        target_pose: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas: Tensor(shape=torch.Size([10, 6]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10  # number of environments to be executed in batch\n",
    "td = env.reset(env.gen_params(batch_size=[batch_size]))\n",
    "print(\"reset (batch size of 10)\", td)\n",
    "td = env.rand_step(td)\n",
    "print(\"rand step (batch size of 10)\", td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "executing a rollout with a batch of data requires us to reset the env\n",
    "out of the rollout function, since we need to define the batch_size\n",
    "dynamically and this is not supported by :func:`EnvBase.rollout`:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_transformation torch.Size([6, 6]) torch.Size([10, 6, 1])\n",
      "stuff\n",
      "torch.Size([10, 6]) torch.Size([10, 6]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000])\n",
      "compute_error_pose torch.Size([10, 6]) torch.Size([10, 6])\n",
      "forward_transformation torch.Size([6, 6]) torch.Size([10, 6, 1])\n",
      "stuff\n",
      "torch.Size([10, 6]) torch.Size([10, 6]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000])\n",
      "compute_error_pose torch.Size([10, 6]) torch.Size([10, 6])\n",
      "forward_transformation torch.Size([6, 6]) torch.Size([10, 6, 1])\n",
      "stuff\n",
      "torch.Size([10, 6]) torch.Size([10, 6]) tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000])\n",
      "compute_error_pose torch.Size([10, 6]) torch.Size([10, 6])\n",
      "forward_transformation torch.Size([6, 6]) torch.Size([10, 6, 1])\n",
      "rollout of len 3 (batch size of 10): TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 3, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        max_theta_deltas: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([10, 3]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                target_pose: Tensor(shape=torch.Size([10, 3, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thetas: Tensor(shape=torch.Size([10, 3, 6]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10, 3]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                max_theta_deltas: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10, 3]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        target_pose: Tensor(shape=torch.Size([10, 3, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thetas: Tensor(shape=torch.Size([10, 3, 6]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([10, 3]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "rollout = env.rollout(\n",
    "    3,\n",
    "    auto_reset=False,  # we're executing the reset out of the ``rollout`` call\n",
    "    tensordict=env.reset(env.gen_params(batch_size=[batch_size])),\n",
    ")\n",
    "print(\"rollout of len 3 (batch size of 10):\", rollout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a simple policy\n",
    "\n",
    "In this example, we will train a simple policy using the reward as a\n",
    "differentiable objective (i.e. a negative loss).\n",
    "We will take advantage of the fact that our dynamic system is fully\n",
    "differentiable to backpropagate through the trajectory return and adjust the\n",
    "weights of our policy to maximise this value directly. Of course, in many\n",
    "settings many of the assumptions we make do not hold, such as\n",
    "differentiability of the system and full access to the underlying mechanics.\n",
    "\n",
    "Still, this is a very simple example that showcases how a training loop can\n",
    "be coded with a custom environment in TorchRL.\n",
    "\n",
    "Let us first write the policy network:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "env.set_seed(0)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(thetas_count),\n",
    ")\n",
    "policy = TensorDictModule(\n",
    "    net,\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and our optimizer:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(policy.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "We will successively:\n",
    "\n",
    "* generate a trajectory\n",
    "* sum the rewards\n",
    "* backpropagate through the graph defined by these operations\n",
    "* clip the gradient norm and make an optimization step\n",
    "* repeat\n",
    "\n",
    "At the end of the training loop, we should have a final reward close to 0\n",
    "which demonstrates that the pendulum is upward and still as desired.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/625 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_transformation torch.Size([6, 6]) torch.Size([32, 6, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "TensorDictModule failed with operation\n    Sequential(\n      (0): LazyLinear(in_features=0, out_features=64, bias=True)\n      (1): Tanh()\n      (2): LazyLinear(in_features=0, out_features=64, bias=True)\n      (3): Tanh()\n      (4): LazyLinear(in_features=0, out_features=64, bias=True)\n      (5): Tanh()\n      (6): LazyLinear(in_features=0, out_features=6, bias=True)\n    )\n    in_keys=['observation']\n    out_keys=['action'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/tensordict/nn/common.py:1164\u001b[0m, in \u001b[0;36mTensorDictModule.forward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1164\u001b[0m     tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/tensordict/nn/common.py:1121\u001b[0m, in \u001b[0;36mTensorDictModule._call_module\u001b[0;34m(self, tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_module\u001b[39m(\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28mself\u001b[39m, tensors: Sequence[Tensor], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   1120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor \u001b[38;5;241m|\u001b[39m Sequence[Tensor]:\n\u001b[0;32m-> 1121\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/tensordict/nn/functional_modules.py:588\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1557\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1557\u001b[0m     args_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torch/nn/modules/lazy.py:250\u001b[0m, in \u001b[0;36mLazyModuleMixin._infer_parameters\u001b[0;34m(self, module, input)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Infers the size and initializes the parameters according to the\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03mprovided input batch.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03mGiven a module that contains parameters that were declared inferrable\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mto avoid saving statistics or calculating gradients\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mhas_uninitialized_params():\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torch/nn/modules/linear.py:257\u001b[0m, in \u001b[0;36mLazyLinear.initialize_parameters\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mmaterialize((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/tensordict/nn/common.py:1172\u001b[0m, in \u001b[0;36mTensorDictModule.forward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     none_set \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1168\u001b[0m         key\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys, tensors)\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m     }\n\u001b[0;32m-> 1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome tensors that are necessary for the module call may \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot have not been found in the input tensordict: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe following inputs are None: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnone_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Some tensors that are necessary for the module call may not have not been found in the input tensordict: the following inputs are None: {'observation'}.\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[196], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m      7\u001b[0m     init_td \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset(env\u001b[38;5;241m.\u001b[39mgen_params(batch_size\u001b[38;5;241m=\u001b[39m[batch_size]))\n\u001b[0;32m----> 8\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_td\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_reset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     traj_return \u001b[38;5;241m=\u001b[39m rollout[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     10\u001b[0m     (\u001b[38;5;241m-\u001b[39mtraj_return)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torchrl/envs/common.py:1235\u001b[0m, in \u001b[0;36mEnvBase.rollout\u001b[0;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, return_contiguous, tensordict)\u001b[0m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_cast_to_device:\n\u001b[1;32m   1234\u001b[0m     tensordict \u001b[38;5;241m=\u001b[39m tensordict\u001b[38;5;241m.\u001b[39mto(policy_device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1235\u001b[0m tensordict \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_cast_to_device:\n\u001b[1;32m   1237\u001b[0m     tensordict \u001b[38;5;241m=\u001b[39m tensordict\u001b[38;5;241m.\u001b[39mto(env_device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/tensordict/nn/functional_modules.py:588\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    590\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*takes \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ positional arguments but \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ were given|got multiple values for argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/tensordict/nn/common.py:282\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest)\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/tensordict/_contextlib.py:126\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/tensordict/nn/utils.py:254\u001b[0m, in \u001b[0;36mset_skip_existing.__call__.<locals>.wrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    249\u001b[0m     skip_existing()\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mkeys(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m out_keys)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m out_keys \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m in_keys)\n\u001b[1;32m    252\u001b[0m ):\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensordict\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/linguamechanica-XFzcHPK6-py3.10/lib/python3.10/site-packages/tensordict/nn/common.py:1204\u001b[0m, in \u001b[0;36mTensorDictModule.forward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1202\u001b[0m in_keys \u001b[38;5;241m=\u001b[39m indent(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1203\u001b[0m out_keys \u001b[38;5;241m=\u001b[39m indent(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1204\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorDictModule failed with operation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1206\u001b[0m ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: TensorDictModule failed with operation\n    Sequential(\n      (0): LazyLinear(in_features=0, out_features=64, bias=True)\n      (1): Tanh()\n      (2): LazyLinear(in_features=0, out_features=64, bias=True)\n      (3): Tanh()\n      (4): LazyLinear(in_features=0, out_features=64, bias=True)\n      (5): Tanh()\n      (6): LazyLinear(in_features=0, out_features=6, bias=True)\n    )\n    in_keys=['observation']\n    out_keys=['action']."
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "pbar = tqdm.tqdm(range(20_000 // batch_size))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, 20_000)\n",
    "logs = defaultdict(list)\n",
    "\n",
    "for _ in pbar:\n",
    "    init_td = env.reset(env.gen_params(batch_size=[batch_size]))\n",
    "    rollout = env.rollout(100, policy, tensordict=init_td, auto_reset=False)\n",
    "    traj_return = rollout[\"next\", \"reward\"].mean()\n",
    "    (-traj_return).backward()\n",
    "    gn = torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    pbar.set_description(\n",
    "        f\"reward: {traj_return: 4.4f}, \"\n",
    "        f\"last reward: {rollout[..., -1]['next', 'reward'].mean(): 4.4f}, gradient norm: {gn: 4.4}\"\n",
    "    )\n",
    "    logs[\"return\"].append(traj_return.item())\n",
    "    logs[\"last_reward\"].append(rollout[..., -1][\"next\", \"reward\"].mean().item())\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "def plot():\n",
    "    import matplotlib\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    is_ipython = \"inline\" in matplotlib.get_backend()\n",
    "    if is_ipython:\n",
    "        from IPython import display\n",
    "\n",
    "    with plt.ion():\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(logs[\"return\"])\n",
    "        plt.title(\"returns\")\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(logs[\"last_reward\"])\n",
    "        plt.title(\"last reward\")\n",
    "        plt.xlabel(\"iteration\")\n",
    "        if is_ipython:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we have learned how to code a stateless environment from\n",
    "scratch. We touched the subjects of:\n",
    "\n",
    "* the four essential components that need to be taken care of when coding\n",
    "  an environment (:func:`step`, :func:`reset\", seeding and building specs).\n",
    "  We saw how these methods and classes interact with the\n",
    "  :class:`tensordict.TensorDict` class;\n",
    "* how to test that an environment is properly coded using\n",
    "  :func:`~torchrl.envs.utils.check_env_specs`;\n",
    "* How to append transforms in the context of stateless environments and how\n",
    "  to write custom transformations;\n",
    "* How to train a policy on a fully differentiable simulator.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
